# verify_master_dataset.py
#
# Description:
# This script verifies the integrity and cleanliness of the master Parquet file
# generated by create_master_dataset.py.
#
# INSTRUCTIONS:
# 1. Run this script after running create_master_dataset.py to ensure the file
#    is ready for backtesting.

import pandas as pd
import os
import sys
import numpy as np
import warnings

# --- SUPPRESS FUTUREWARNING ---
warnings.simplefilter(action='ignore', category=FutureWarning)

# ==============================================================================
# --- CONFIGURATION SETTINGS ---
# ==============================================================================

# The project root directory is determined automatically to build all other file paths.
# FIXED: Hard-code the root directory to fix the file path issue.
ROOT_DIR = "D:\\algo-2025"

# The path to the master Parquet file
MASTER_FILE_PATH = os.path.join(ROOT_DIR, "data", "all_signals_master.parquet")


# ==============================================================================
# --- VERIFICATION ENGINE ---
# ==============================================================================

def verify_master_file():
    """
    Performs a series of integrity checks on the master Parquet file.
    """
    print("--- Starting Master File Verification ---")

    # 1. File existence and size check
    if not os.path.exists(MASTER_FILE_PATH):
        print(f"❌ ERROR: Master file not found at: {MASTER_FILE_PATH}")
        return False
    
    file_size_mb = os.path.getsize(MASTER_FILE_PATH) / (1024 * 1024)
    print(f"✅ File found. Size: {file_size_mb:.2f} MB")

    try:
        # Load the entire DataFrame
        master_df = pd.read_parquet(MASTER_FILE_PATH)
        print(f"✅ File loaded successfully. Total rows: {len(master_df)}")

        if master_df.empty:
            print("❌ ERROR: The DataFrame is empty.")
            return False

        # 2. Column verification
        required_columns = ['symbol', 'open', 'high', 'low', 'close', 'volume', 'signal', 'entry_price', 'sl']
        missing_columns = [col for col in required_columns if col not in master_df.columns]
        if missing_columns:
            print(f"❌ ERROR: Missing required columns: {missing_columns}")
            return False
        else:
            print("✅ All required columns are present.")

        # 3. Data type verification
        print("\n--- Data Type Check ---")
        for col in master_df.columns:
            if master_df[col].dtype == 'float64':
                print(f"  - WARNING: Column '{col}' is float64. Downcasting may have failed.")
            elif master_df[col].dtype == 'int64':
                print(f"  - WARNING: Column '{col}' is int64. Downcasting may have failed.")
            else:
                print(f"  - OK: Column '{col}' has a smaller data type ({master_df[col].dtype}).")
        
        # 4. Missing values check in critical columns
        critical_columns = ['open', 'high', 'low', 'close']
        for col in critical_columns:
            if master_df[col].isnull().any():
                print(f"❌ ERROR: Found missing values in column '{col}'.")
                return False
        print("\n✅ No missing values found in critical columns.")

        # New Check for NaNs in 'entry_price' and 'sl' only for rows with a signal.
        signal_entries = master_df[master_df['signal'] != 0].copy()
        if signal_entries.empty:
            print("❌ WARNING: No signals were generated in the entire dataset. Check your configurations.")
        else:
            if signal_entries['entry_price'].isnull().any() or signal_entries['sl'].isnull().any():
                print(f"❌ ERROR: Found missing values in 'entry_price' or 'sl' columns for rows with signals.")
                return False
            print("✅ No missing values found in 'entry_price' and 'sl' for rows with signals.")
            
        # 5. Chronological order check
        if not master_df.index.is_monotonic_increasing:
            print("❌ ERROR: The DataFrame index is not in chronological order.")
            return False
        else:
            print("✅ DataFrame index is in chronological order.")

        # 6. Spot Check a few signals
        if not signal_entries.empty:
            print("\n--- Signal Spot Check ---")
            sample_signals = signal_entries.sample(min(5, len(signal_entries)), random_state=42)
            print("✅ Found signals. Here are a few random samples:")
            print(sample_signals[['symbol', 'signal', 'entry_price', 'sl']].to_string())

        print("\n--- Verification Complete! The master file is ready for backtesting. ---")
        return True

    except Exception as e:
        print(f"❌ An unexpected error occurred during verification: {e}")
        return False

if __name__ == "__main__":
    verify_master_file()
