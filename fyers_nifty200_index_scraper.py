# fyers_nifty200_index_scraper.py
#
# Description:
# This script downloads historical daily data for a single specified symbol (index or equity).
# It can be controlled via command-line arguments to specify the symbol and its type.
#
# Prerequisites:
# 1. A Fyers trading account and API App credentials.
# 2. A 'config.py' file with your credentials.
# 3. An existing 'fyers_access_token.txt' file (generated by your main scraper).
# 4. Required libraries installed: pip install fyers-apiv3 pandas

import os
import sys
import pandas as pd
from datetime import datetime, timedelta
import time
import argparse

# --- Import Configuration ---
try:
    from config import CLIENT_ID, SECRET_KEY, REDIRECT_URI
except ImportError:
    print("Error: Could not import from config.py.")
    print("Please make sure you have a config.py file with CLIENT_ID, SECRET_KEY, and REDIRECT_URI defined.")
    sys.exit()

# --- Import Fyers API Module ---
from fyers_apiv3 import fyersModel

# --- Script Configuration ---
LOG_PATH = os.getcwd()
TOKEN_FILE = "fyers_access_token.txt"
START_DATE = "2020-01-01" # Fetch data from this date onwards

def get_access_token():
    """Reads the existing access token from the file."""
    if os.path.exists(TOKEN_FILE):
        with open(TOKEN_FILE, 'r') as f:
            return f.read().strip()
    else:
        print("Error: fyers_access_token.txt not found.")
        print("Please run your main 'fyers_equity_scraper.py' script once to generate the token file.")
        return None

# --- Fyers API Client Initialization ---
access_token = get_access_token()

if not access_token:
    sys.exit()

try:
    fyers = fyersModel.FyersModel(
        client_id=CLIENT_ID,
        is_async=False,
        token=access_token,
        log_path=LOG_PATH
    )
    print("Fyers API client initialized successfully.")
    profile = fyers.get_profile()
    if profile['s'] != 'ok':
         print("Profile fetch failed. The access token might be invalid.")
         print("Please delete fyers_access_token.txt and run your main scraper again to regenerate it.")
         sys.exit()
    print(f"Welcome, {profile['data']['name']}!")
except Exception as e:
    print(f"Error initializing Fyers API client: {e}")
    sys.exit()

def get_historical_data(symbol, resolution, from_date, to_date, retries=3, delay=2):
    """
    Fetches historical OHLC data for a given security with a retry mechanism.
    """
    data = {
        "symbol": symbol,
        "resolution": resolution,
        "date_format": "1",
        "range_from": from_date,
        "range_to": to_date,
        "cont_flag": "1"
    }
    
    for i in range(retries):
        try:
            response = fyers.history(data=data)
            if response.get("s") == 'ok':
                candles = response.get('candles', [])
                if not candles:
                    return pd.DataFrame()
                
                df = pd.DataFrame(candles, columns=['datetime', 'open', 'high', 'low', 'close', 'volume'])
                df['datetime'] = pd.to_datetime(df['datetime'], unit='s')
                df['datetime'] = df['datetime'] + pd.Timedelta(hours=5, minutes=30)
                df.set_index('datetime', inplace=True)
                return df
            else:
                print(f"    - API Error (Attempt {i+1}/{retries}): {response.get('message', 'Unknown error')}")
                if i < retries - 1:
                    time.sleep(delay)
        except Exception as e:
            print(f"    - An exception occurred (Attempt {i+1}/{retries}): {e}")
            if i < retries - 1:
                time.sleep(delay)

    print(f"    - Failed to fetch data for {symbol} after {retries} attempts.")
    return pd.DataFrame()

if __name__ == "__main__":
    # --- Command-Line Argument Parsing ---
    parser = argparse.ArgumentParser(description="Fyers Historical Data Scraper for a single symbol.")
    parser.add_argument(
        '--symbol',
        type=str,
        default='NIFTY200',
        help='The symbol to download (e.g., NIFTY200, RELIANCE, SBIN).'
    )
    parser.add_argument(
        '--type',
        type=str,
        default='index',
        choices=['index', 'equity'],
        help="The type of the symbol ('index' or 'equity')."
    )
    args = parser.parse_args()

    # --- Dynamic Symbol and Filename Configuration ---
    if args.type == 'index':
        fyers_symbol = f"NSE:{args.symbol}-INDEX"
        output_filename = f"{args.symbol}_INDEX_daily.csv"
    else:  # equity
        fyers_symbol = f"NSE:{args.symbol}-EQ"
        output_filename = f"{args.symbol}_EQ_daily.csv"

    output_dir = "historical_data"
    os.makedirs(output_dir, exist_ok=True)
    
    output_path = os.path.join(output_dir, output_filename)
    
    print(f"\nFetching historical data for {args.symbol} ({args.type})...")
    print(f"Fyers Symbol: {fyers_symbol}")
    print(f"Date Range: {START_DATE} to Today")

    # --- BATCHING LOGIC ---
    all_data_batches = []
    from_date = pd.to_datetime(START_DATE).date()
    to_date = datetime.now()

    batch_start_date = from_date
    while batch_start_date <= to_date.date():
        batch_end_dt = pd.to_datetime(batch_start_date) + pd.DateOffset(months=6) - timedelta(days=1)
        if batch_end_dt > to_date:
            batch_end_dt = to_date

        from_date_str = batch_start_date.strftime('%Y-%m-%d')
        to_date_str = batch_end_dt.strftime('%Y-%m-%d')
        
        print(f"    > Fetching batch: {from_date_str} to {to_date_str}")
        
        batch_df = get_historical_data(fyers_symbol, "D", from_date_str, to_date_str)
        
        if not batch_df.empty:
            all_data_batches.append(batch_df)
        
        time.sleep(1.1)
        batch_start_date = batch_end_dt.date() + timedelta(days=1)

    if all_data_batches:
        final_df = pd.concat(all_data_batches)
        final_df.to_csv(output_path, mode='w', header=True)
        print(f"\nSuccess: Saved {len(final_df)} records to {output_path}")
    else:
        print(f"\nInfo: No data returned for {args.symbol}.")
        
    print("\n--- Data download complete! ---")
