# fix_corrupted_data.py
#
# Description:
# This script scans a directory for corrupted CSV files generated by the old
# data scraper and cleans them. It identifies files with extra index columns,
# keeps the correct datetime column, and overwrites the file with a clean,
# properly formatted version.
#
# INSTRUCTIONS:
# 1. Place this script in your project's root directory (e.g., D:\algo-2025).
# 2. Run it once from your terminal: python fix_corrupted_data.py
# 3. This will permanently fix all the corrupted data files in place.

import os
import pandas as pd

# --- CONFIGURATION ---
# Set the directory where your raw 15min and daily CSV files are stored.
DATA_DIRECTORY = os.path.join("data", "universal_historical_data")

def clean_csv_file(filepath):
    """
    Reads a CSV file, checks for the corrupted header, and fixes it.
    """
    try:
        # Read only the header to check for corruption without loading the whole file
        header = pd.read_csv(filepath, nrows=0).columns.tolist()
        
        # The corrupted format has specific, repeated column names
        if 'datetime' in header and 'datetime.1' in header:
            print(f"  - Fixing corrupted file: {os.path.basename(filepath)}")
            
            # Read the corrupted data, using the correct datetime column
            df = pd.read_csv(filepath, usecols=['datetime.1', 'open', 'high', 'low', 'close', 'volume'])
            
            # Rename the column to the correct 'datetime'
            df.rename(columns={'datetime.1': 'datetime'}, inplace=True)
            
            # Overwrite the original file with the cleaned data
            # The index=False flag is crucial to prevent creating a new unnamed index column
            df.to_csv(filepath, index=False)
            return True
        else:
            # The file is already in the correct format
            return False
            
    except Exception as e:
        print(f"  - Error processing {os.path.basename(filepath)}: {e}")
        return False

def main():
    """
    Main function to find and clean all CSV files in the target directory.
    """
    print(f"--- Starting Data Cleaning Process ---")
    print(f"Target Directory: {DATA_DIRECTORY}\n")
    
    if not os.path.isdir(DATA_DIRECTORY):
        print(f"Error: Directory not found at '{DATA_DIRECTORY}'. Please check the path.")
        return

    cleaned_count = 0
    total_files = 0
    
    # Walk through the directory to find all .csv files
    for root, _, files in os.walk(DATA_DIRECTORY):
        for file in files:
            if file.endswith('.csv'):
                total_files += 1
                filepath = os.path.join(root, file)
                if clean_csv_file(filepath):
                    cleaned_count += 1
    
    print("\n--- Data Cleaning Complete! ---")
    print(f"Scanned {total_files} CSV files.")
    print(f"Fixed {cleaned_count} corrupted files.")

if __name__ == "__main__":
    main()
