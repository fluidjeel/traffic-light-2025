# trade_validator.py
#
# Description:
# A standalone script to audit and validate the trade logs generated by the
# daily_long_breakout.py backtester. It builds confidence in the backtest results
# by independently verifying the logic and calculations for a sample of trades.
#
# v5 Update (Parser Bug Fix):
# - Fixed a critical bug in the config parser that was incorrectly reading simple
#   lists (e.g., [15, 22]) as strings. The parser now correctly handles all
#   JSON-style list formats, resolving the numpy comparison error.

import pandas as pd
import os
import glob
import json
import numpy as np

def parse_human_readable_config(summary_content):
    """
    Parses the human-readable config from the summary file into a dictionary.
    """
    config = {}
    current_section_dict = None
    
    config_str = summary_content.split('PERFORMANCE SUMMARY')[0]
    
    for line in config_str.split('\n'):
        original_line = line
        line = line.strip()

        if not line or "BACKTEST PARAMETERS" in line or "===" in line:
            continue
        
        if line.startswith('[') and line.endswith(']'):
            section_name = line[1:-1].lower().replace(' ', '_')
            config[section_name] = {}
            current_section_dict = config[section_name]
            continue
        
        if not original_line.startswith('  '):
            current_section_dict = None

        if ':' in line:
            key, value = line.split(':', 1)
            key = key.strip()
            value = value.strip()
            
            # --- FIX: Handle all list types first ---
            if isinstance(value, str) and value.startswith('['):
                try:
                    # Use json.loads for robust parsing of lists like [1, 2] or [[1,2], [3,4]]
                    value = json.loads(value.replace("'", '"'))
                except json.JSONDecodeError:
                    pass # Keep as string if it's not a valid list
            else:
                try:
                    if '.' in value and not any(c.isalpha() for c in value):
                        value = float(value)
                    elif value.isdigit() or (value.startswith('-') and value[1:].isdigit()):
                         value = int(value)
                except ValueError:
                    pass

                if value == 'True': value = True
                elif value == 'False': value = False

            if current_section_dict is not None:
                current_section_dict[key] = value
            else:
                config[key] = value
                    
    return config

def get_expected_risk_percent(vix_value, config):
    """Replicates the backtester's dynamic risk calculation."""
    dr_cfg = config['dynamic_risk']
    if not dr_cfg['enabled'] or pd.isna(vix_value):
        return config['risk_per_trade_percent']
    
    if vix_value <= dr_cfg['vix_thresholds'][0]:
        return dr_cfg['risk_percents'][0]
    elif vix_value <= dr_cfg['vix_thresholds'][1]:
        return dr_cfg['risk_percents'][1]
    else:
        return dr_cfg['risk_percents'][2]

def run_validation():
    """
    Main function to find the latest backtest run and validate its trade log.
    """
    print("\n" + "="*80)
    print("--- RUNNING TRADE LOG VALIDATOR ---")
    print("="*80)

    # --- 1. Find the Latest Backtest Run ---
    log_root_folder = 'backtest_logs'
    if not os.path.exists(log_root_folder):
        print(f"Error: Log directory '{log_root_folder}' not found. Please run a backtest first.")
        return

    all_timestamped_runs = []
    strategy_folders = [os.path.join(log_root_folder, d) for d in os.listdir(log_root_folder) if os.path.isdir(os.path.join(log_root_folder, d))]

    for folder in strategy_folders:
        timestamp_folders = [os.path.join(folder, d) for d in os.listdir(folder) if os.path.isdir(os.path.join(folder, d))]
        all_timestamped_runs.extend(timestamp_folders)

    if not all_timestamped_runs:
        print("No backtest run folders found in the log directory.")
        return
    
    latest_run_folder = max(all_timestamped_runs, key=os.path.getmtime)
    print(f"Found latest backtest run: {os.path.basename(latest_run_folder)}")

    trade_log_path = glob.glob(os.path.join(latest_run_folder, '*_all_trades.csv'))
    summary_path = glob.glob(os.path.join(latest_run_folder, '*_summary.txt'))

    if not trade_log_path or not summary_path:
        print("Error: Could not find the required trade log or summary file in the latest run folder.")
        return

    # --- 2. Load Config and Trade Data ---
    try:
        with open(summary_path[0], 'r') as f:
            summary_content = f.read()
            config = parse_human_readable_config(summary_content)
        
        trades_df = pd.read_csv(trade_log_path[0], parse_dates=['setup_candle_date', 'entry_date', 'exit_date'])
        print(f"Successfully loaded config and {len(trades_df)} trades for validation.")
    except Exception as e:
        print(f"Error loading files: {e}")
        return

    # --- 3. Randomly Sample Trades for Deep Dive ---
    sample_size = min(5, len(trades_df))
    if sample_size == 0:
        print("No trades in the log to validate.")
        return
        
    sampled_trades = trades_df.sample(n=sample_size)
    print(f"Randomly sampling {sample_size} trades for a deep-dive validation...\n")

    # --- 4. Load Raw Data for Validation ---
    data_folder = config['data_folder']
    all_stock_data = {}
    
    # Load VIX data once for all validations
    vix_df = None
    vix_path = os.path.join(data_folder, f"{config['vix_symbol']}_daily_with_indicators.csv")
    if os.path.exists(vix_path):
        vix_df = pd.read_csv(vix_path, index_col='datetime', parse_dates=True)
        vix_df.rename(columns=lambda x: x.lower(), inplace=True)
    else:
        print("Warning: VIX data file not found. Cannot validate position sizing.")

    for index, trade in sampled_trades.iterrows():
        symbol = trade['symbol']
        if symbol not in all_stock_data:
            file_path = os.path.join(data_folder, f"{symbol}_daily_with_indicators.csv")
            if os.path.exists(file_path):
                all_stock_data[symbol] = pd.read_csv(file_path, index_col='datetime', parse_dates=True)
                all_stock_data[symbol].rename(columns=lambda x: x.lower(), inplace=True)
            else:
                print(f"Warning: Data file not found for {symbol}. Cannot validate this trade.")
                continue
        
        validate_single_trade(trade, all_stock_data[symbol], config, vix_df)


def validate_single_trade(trade, stock_df, config, vix_df):
    """
    Performs a deep-dive validation for a single trade.
    """
    ef_cfg = config['entry_filters']
    tm_cfg = config['trade_management']
    symbol = trade['symbol']
    
    print("-" * 80)
    print(f"VALIDATING TRADE: {symbol} | Entry: {trade['entry_date'].date()} | Exit: {trade['exit_date'].date()}")
    print("-" * 80)

    # --- A. Validate Setup Day ---
    try:
        setup_candle = stock_df.loc[trade['setup_candle_date']]
        print("A. SETUP DAY VALIDATION:")
        vol_check = setup_candle['volume_ratio'] >= ef_cfg['min_volume_ratio']
        print(f"  - Volume Ratio Check: Actual={setup_candle['volume_ratio']:.2f}, Required>={ef_cfg['min_volume_ratio']}. -> {'PASS' if vol_check else 'FAIL'}")
        ema_val = setup_candle[f"ema_{ef_cfg['ema_period']}"]
        ema_check = setup_candle['close'] > ema_val
        print(f"  - EMA Trend Check: Close={setup_candle['close']:.2f}, EMA={ema_val:.2f}. -> {'PASS' if ema_check else 'FAIL'}")
        rsi_val = setup_candle['rsi_14']
        rsi_in_range = any(low <= rsi_val <= high for low, high in ef_cfg['rsi_ranges'])
        print(f"  - RSI Range Check: Actual={rsi_val:.2f}, Required in {ef_cfg['rsi_ranges']}. -> {'PASS' if rsi_in_range else 'FAIL'}")
    except KeyError:
        print("  - ERROR: Could not find setup_candle_date in the data file.")

    # --- B. Validate Entry Day ---
    try:
        setup_candle = stock_df.loc[trade['setup_candle_date']]
        entry_day_candle = stock_df.loc[trade['entry_date']]
        print("\nB. ENTRY DAY VALIDATION:")
        trigger_price = setup_candle['high']
        entry_feasible = entry_day_candle['high'] >= trigger_price
        print(f"  - Entry Feasibility: Day High={entry_day_candle['high']:.2f}, Trigger>={trigger_price:.2f}. -> {'PASS' if entry_feasible else 'FAIL'}")
    except KeyError:
        print("  - ERROR: Could not find entry_date or setup_candle_date in the data file.")

    # --- C. Validate Position Sizing ---
    print("\nC. POSITION SIZING VALIDATION:")
    if vix_df is not None:
        try:
            vix_on_entry_day = vix_df.loc[trade['entry_date']]['close']
            expected_risk = get_expected_risk_percent(vix_on_entry_day, config)
            logged_risk = trade['risk_pct_at_entry']
            sizing_valid = np.isclose(expected_risk, logged_risk)
            print(f"  - Dynamic Risk Check: Logged={logged_risk:.2f}%, Recalculated={expected_risk:.2f}%. -> {'PASS' if sizing_valid else 'FAIL'}")
        except KeyError:
            print("  - ERROR: Could not find VIX data for the entry date.")
    else:
        print("  - SKIPPED: VIX data not available.")

    # --- D. Validate Trailing Stop & Exit ---
    print("\nD. TRAILING STOP & EXIT VALIDATION:")
    try:
        trade_period_df = stock_df.loc[trade['entry_date']:trade['exit_date']]
        simulated_stop = trade['initial_stop_loss']
        simulated_high = trade['entry_price']
        breakeven_triggered = False

        for idx, day in enumerate(trade_period_df.index):
            if day == trade['exit_date']:
                break # We only simulate up to the day before the exit
            
            daily_candle = trade_period_df.loc[day]
            simulated_high = max(simulated_high, daily_candle['high'])

            if not breakeven_triggered and tm_cfg['use_breakeven']:
                if daily_candle['close'] > trade['entry_price']:
                    simulated_stop = max(simulated_stop, trade['entry_price'] * (1 + tm_cfg['breakeven_buffer_percent'] / 100))
                    breakeven_triggered = True
            
            # Use T-1 ATR
            prev_day_idx = stock_df.index.get_loc(day) - 1
            if prev_day_idx >= 0:
                prev_day_data = stock_df.iloc[prev_day_idx]
                atr_val = prev_day_data.get(f"atr_{tm_cfg['atr_period']}", 0)
                
                atr_mult = tm_cfg['atr_multiplier']
                dyn_atr_cfg = tm_cfg.get('dynamic_atr')
                if dyn_atr_cfg and dyn_atr_cfg['enabled']:
                    if trade['rsi_at_entry'] < dyn_atr_cfg['rsi_threshold']:
                        atr_mult = dyn_atr_cfg['low_rsi_multiplier']
                    else:
                        atr_mult = dyn_atr_cfg['high_rsi_multiplier']
                
                simulated_stop = max(simulated_stop, simulated_high - (atr_val * atr_mult))
        
        exit_day_candle = trade_period_df.iloc[-1]
        exit_valid = exit_day_candle['low'] <= simulated_stop
        print(f"  - Exit Trigger Check: Exit Day Low={exit_day_candle['low']:.2f}, Simulated Stop<={simulated_stop:.2f}. -> {'PASS' if exit_valid else 'FAIL'}")

    except Exception as e:
        print(f"  - ERROR: An error occurred during trailing stop simulation: {e}")


    # --- E. Validate PnL Calculation ---
    print("\nE. PNL CALCULATION VALIDATION:")
    recalculated_pnl = (trade['exit_price'] - trade['entry_price']) * trade['shares']
    pnl_matches = np.isclose(recalculated_pnl, trade['pnl'])
    print(f"  - PnL Check: Logged={trade['pnl']:,.2f}, Recalculated={recalculated_pnl:,.2f}. -> {'PASS' if pnl_matches else 'FAIL'}")
    print("\n")


if __name__ == "__main__":
    run_validation()
